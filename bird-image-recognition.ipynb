{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4,5'\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configs & Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size\n",
    "batch_size = 32\n",
    "# validation split\n",
    "valid_size = .1\n",
    "# test split\n",
    "test_size = 0.2\n",
    "\n",
    "img_dim = (200, 200)\n",
    "\n",
    "# paths\n",
    "cache_path = 'cache'\n",
    "data_path = 'data-filtered'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images for '.ipynb_checkpoints'\n",
      "Not enough data for '.ipynb_checkpoints'\n",
      "Loading images for 'Aberrant Bush-Warbler'\n",
      "271 images loaded for 'Aberrant Bush-Warbler'\n",
      "Loading images for 'Ala Shan Redstart'\n",
      "401 images loaded for 'Ala Shan Redstart'\n",
      "Loading images for 'Aleutian Tern'\n",
      "282 images loaded for 'Aleutian Tern'\n",
      "Loading images for 'Altai Snowcock'\n",
      "244 images loaded for 'Altai Snowcock'\n",
      "Loading images for 'American Wigeon'\n",
      "486 images loaded for 'American Wigeon'\n",
      "Loading images for 'Arctic Warbler'\n",
      "329 images loaded for 'Arctic Warbler'\n",
      "Loading images for 'Ashy Bulbul'\n",
      "310 images loaded for 'Ashy Bulbul'\n",
      "Loading images for 'Ashy Drongo'\n",
      "412 images loaded for 'Ashy Drongo'\n",
      "Loading images for 'Ashy Minivet'\n",
      "443 images loaded for 'Ashy Minivet'\n",
      "Loading images for 'Ashy Wood Pigeon'\n",
      "335 images loaded for 'Ashy Wood Pigeon'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "n_birds = 10 # use ten kinds of birds first\n",
    "bird_file_map = {}\n",
    "\n",
    "# return array of bird names\n",
    "birdList = sorted(os.listdir(data_path))\n",
    "loadedImages = []\n",
    "\n",
    "n_images = 0\n",
    "n_birds_loaded = 0\n",
    "for b in birdList:\n",
    "    if n_birds_loaded >= n_birds:\n",
    "        break\n",
    "    print(\"Loading images for '\" + b + \"'\")\n",
    "    curdir = os.path.join(data_path, b)\n",
    "    if not os.path.isdir(curdir):\n",
    "        continue\n",
    "    img_files = os.listdir(curdir)\n",
    "    \n",
    "    filenames = [os.path.join(curdir, f) for f in img_files]\n",
    "    n_f = len(filenames)\n",
    "    if n_f > 0: # use data only if more than xx images are found\n",
    "        bird_file_map[b] = filenames\n",
    "        print(n_f, \"images loaded for '\" + b + \"'\")\n",
    "        n_birds_loaded += 1\n",
    "        n_images += n_f\n",
    "    else:\n",
    "        print(\"Not enough data for '\" + b + \"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "n_channels = 3\n",
    "X = np.zeros((n_images, img_dim[0], img_dim[1], n_channels))\n",
    "labels = []\n",
    "\n",
    "i = 0\n",
    "for k, v in bird_file_map.items():\n",
    "    for file in v:\n",
    "        try:\n",
    "            im = cv2.imread(file)\n",
    "            if im is None or im.shape[0] < img_dim[0] or im.shape[1] < img_dim[1]:\n",
    "                continue\n",
    "            shape = im.shape\n",
    "            assert len(shape) == 3 # width, length and color channels\n",
    "            assert shape[-1] == 3 # rgb, three channels\n",
    "            \n",
    "            # resizing\n",
    "            im = cv2.resize(src=im, dsize=img_dim, interpolation=cv2.INTER_LINEAR)\n",
    "            # Gaussian blurring\n",
    "            # im = cv2.GaussianBlur(im, (5, 5), 0)\n",
    "            X[i] = np.asarray(im)\n",
    "            labels.append(k)\n",
    "            i += 1\n",
    "        except IOError:\n",
    "            continue\n",
    "n_images = len(labels)\n",
    "X = X[:n_images, ]\n",
    "del i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_unique = list(set(labels))\n",
    "\n",
    "Y = np.zeros((n_images, 1))\n",
    "for i in range(n_images):\n",
    "    Y[i, 0] = labels_unique.index(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2138, 200, 200, 3)\n",
      "(2138, 1)\n",
      "0.0 255.0\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(np.min(X), np.max(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(X.shape[0]):\n",
    "    m = np.min(X[i,])\n",
    "    X[i] = (X[i,] - m) / (np.max(X[i,]) - m)\n",
    "\n",
    "print(np.min(X), np.max(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducing memory size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 489.35 Mb (75.0% reduction)\n",
      "Mem. usage decreased to  0.00 Mb (75.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "# Function to reduce the numpy array size\n",
    "def reduce_mem_usage(a, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = a.nbytes / 1024**2\n",
    "    dtype = a.dtype\n",
    "    if dtype in numerics:\n",
    "        c_min = a.min()\n",
    "        c_max = a.max()\n",
    "        if str(dtype)[:3] == 'int':\n",
    "            if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                a = a.astype(np.int8)\n",
    "            elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                a = a.astype(np.int16)\n",
    "            elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                a = a.astype(np.int32)\n",
    "            elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                a = a.astype(np.int64)  \n",
    "        else:\n",
    "            if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                a = a.astype(np.float16)\n",
    "            elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                a = a.astype(np.float32)\n",
    "            else:\n",
    "                a = a.astype(np.float64)\n",
    "    end_mem = a.nbytes / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return a\n",
    "\n",
    "X = reduce_mem_usage(X)\n",
    "Y = reduce_mem_usage(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=valid_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data augmentation sucessful, 1539 new images in total were added\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "img_gen_batch_size = 32\n",
    "image_gen_train = ImageDataGenerator(\n",
    "                    rotation_range=45,\n",
    "                    width_shift_range=0.2,\n",
    "                    height_shift_range=0.2,\n",
    "                    horizontal_flip=True,\n",
    "                    shear_range=0.2,\n",
    "                    zoom_range=0.1)\n",
    "\n",
    "image_gen_flow = image_gen_train.flow(X_train, y_train, batch_size=img_gen_batch_size)\n",
    "X_added = np.zeros((len(image_gen_flow) * img_gen_batch_size, *(X_train.shape[1:])))\n",
    "Y_added = np.zeros((len(image_gen_flow) * img_gen_batch_size, *(y_train.shape[1:])))\n",
    "flow_len = len(image_gen_flow)\n",
    "\n",
    "n_added = 0\n",
    "for i in range(0, flow_len):\n",
    "    X_batch = image_gen_flow[i][0]\n",
    "    img_gen_batch_size = X_batch.shape[0]\n",
    "    X_added[i * img_gen_batch_size: (i + 1) * img_gen_batch_size,] = X_batch\n",
    "    Y_added[i * img_gen_batch_size: (i + 1) * img_gen_batch_size,] = image_gen_flow[i][1]\n",
    "    n_added += img_gen_batch_size\n",
    "print('data augmentation sucessful, {} new images in total were added'.format(n_added))\n",
    "del flow_len\n",
    "del X_batch\n",
    "del img_gen_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.vstack([X_train, X_added])\n",
    "y_train = np.vstack([y_train, Y_added])\n",
    "del X_added\n",
    "del Y_added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3107, 200, 200, 3) | (428, 200, 200, 3)\n",
      "(3107, 10) | (428, 10) | (171, 10)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_valid = to_categorical(y_valid)\n",
    "print(X_train.shape, '|', X_test.shape)\n",
    "print(y_train.shape, '|', y_test.shape, '|', y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 198, 198, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 196, 196, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 98, 98, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 96, 96, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 94, 94, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 47, 47, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 45, 45, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 43, 43, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 41, 41, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 20, 20, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 102400)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               52429312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 54,330,314\n",
      "Trainable params: 54,330,314\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_classes = n_birds\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(64, 3, strides=1, input_shape=(img_dim[0], img_dim[1], 3)))\n",
    "model.add(layers.Conv2D(64, 3, strides=1))\n",
    "model.add(layers.MaxPooling2D(2, strides=2))\n",
    "\n",
    "model.add(layers.Conv2D(128, 3, strides=1))\n",
    "model.add(layers.Conv2D(128, 3, strides=1))\n",
    "model.add(layers.MaxPooling2D(2, strides=2))\n",
    "\n",
    "model.add(layers.Conv2D(256, 3, strides=1))\n",
    "model.add(layers.Conv2D(256, 3, strides=1))\n",
    "model.add(layers.Conv2D(256, 3, strides=1))\n",
    "model.add(layers.MaxPooling2D(2, strides=2))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(n_classes, activation='relu'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3107 samples\n",
      "Epoch 1/20\n",
      "3107/3107 [==============================] - 21s 7ms/sample - loss: 8.7213 - accuracy: 0.1175\n",
      "Epoch 2/20\n",
      "3107/3107 [==============================] - 16s 5ms/sample - loss: 8.5887 - accuracy: 0.1271\n",
      "Epoch 3/20\n",
      "3107/3107 [==============================] - 16s 5ms/sample - loss: 6.7485 - accuracy: 0.1207\n",
      "Epoch 4/20\n",
      "3107/3107 [==============================] - 16s 5ms/sample - loss: 5.7078 - accuracy: 0.1201\n",
      "Epoch 5/20\n",
      "3107/3107 [==============================] - 16s 5ms/sample - loss: 5.7057 - accuracy: 0.1316\n",
      "Epoch 6/20\n",
      "3107/3107 [==============================] - 17s 5ms/sample - loss: 5.7039 - accuracy: 0.1316\n",
      "Epoch 7/20\n",
      "3107/3107 [==============================] - 16s 5ms/sample - loss: 5.7025 - accuracy: 0.1423\n",
      "Epoch 8/20\n",
      "3107/3107 [==============================] - 16s 5ms/sample - loss: 5.6964 - accuracy: 0.1558\n",
      "Epoch 9/20\n",
      "3107/3107 [==============================] - 16s 5ms/sample - loss: 5.6773 - accuracy: 0.1690\n",
      "Epoch 10/20\n",
      "3107/3107 [==============================] - 15s 5ms/sample - loss: 5.6426 - accuracy: 0.1989\n",
      "Epoch 11/20\n",
      "3107/3107 [==============================] - 14s 4ms/sample - loss: 5.6794 - accuracy: 0.1825\n",
      "Epoch 12/20\n",
      "3107/3107 [==============================] - 15s 5ms/sample - loss: 5.6553 - accuracy: 0.1860\n",
      "Epoch 13/20\n",
      "3107/3107 [==============================] - 16s 5ms/sample - loss: 5.7016 - accuracy: 0.1329\n",
      "Epoch 14/20\n",
      "3107/3107 [==============================] - 16s 5ms/sample - loss: 5.7005 - accuracy: 0.1361\n",
      "Epoch 15/20\n",
      "3107/3107 [==============================] - 16s 5ms/sample - loss: 5.6962 - accuracy: 0.1471\n",
      "Epoch 16/20\n",
      "3107/3107 [==============================] - 16s 5ms/sample - loss: 5.6836 - accuracy: 0.1616\n",
      "Epoch 17/20\n",
      "3107/3107 [==============================] - 16s 5ms/sample - loss: 5.6560 - accuracy: 0.1835\n",
      "Epoch 18/20\n",
      "3107/3107 [==============================] - 16s 5ms/sample - loss: 5.6339 - accuracy: 0.2140\n",
      "Epoch 19/20\n",
      "3107/3107 [==============================] - 16s 5ms/sample - loss: 5.6238 - accuracy: 0.2105\n",
      "Epoch 20/20\n",
      "3107/3107 [==============================] - 14s 5ms/sample - loss: 5.6428 - accuracy: 0.2070\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428/1 - 1s - loss: 4.7592 - accuracy: 0.2407\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
